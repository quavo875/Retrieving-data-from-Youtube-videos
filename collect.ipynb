{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6139240-3b34-461a-80ef-4320364f26db",
   "metadata": {
    "tags": []
   },
   "source": [
    "### A. Imports\n",
    "You need to import the following libraries. Install the libraries using \"conda install ... or pip install ...\" if they have not been installed on your machine. For example you can install google api python client by executing \"conda install google-api-python-client\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "14131785-ec21-4364-96fc-7d930999ba5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google-api-python-client module not found. Installing...\n",
      "Requirement already satisfied: google-api-python-client in /Users/krish/Downloads/myenv/lib/python3.12/site-packages (2.130.0)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /Users/krish/Downloads/myenv/lib/python3.12/site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /Users/krish/Downloads/myenv/lib/python3.12/site-packages (from google-api-python-client) (2.29.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /Users/krish/Downloads/myenv/lib/python3.12/site-packages (from google-api-python-client) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /Users/krish/Downloads/myenv/lib/python3.12/site-packages (from google-api-python-client) (2.19.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/krish/Downloads/myenv/lib/python3.12/site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/krish/Downloads/myenv/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.63.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /Users/krish/Downloads/myenv/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (4.25.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/krish/Downloads/myenv/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.23.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /Users/krish/Downloads/myenv/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.32.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/krish/Downloads/myenv/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/krish/Downloads/myenv/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/krish/Downloads/myenv/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/krish/Downloads/myenv/lib/python3.12/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/krish/Downloads/myenv/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/krish/Downloads/myenv/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/krish/Downloads/myenv/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/krish/Downloads/myenv/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/krish/Downloads/myenv/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2024.2.2)\n",
      "All required modules are installed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/krish/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import subprocess\n",
    "\n",
    "# The following lines should install all libraries you need - you can install the libraries manually if the script did not work \n",
    "required_modules = ['pandas', 'seaborn', 'matplotlib', 'google-api-python-client', 'datetime', 'configparser', 'nltk', 'langdetect', 'textblob', 'prettytable', 'tabulate', 'numpy']\n",
    "for module in required_modules:\n",
    "    try:\n",
    "        importlib.import_module(module)\n",
    "    except ImportError:\n",
    "        print(f\"{module} module not found. Installing...\")\n",
    "        subprocess.check_call(['pip', 'install', module])\n",
    "\n",
    "print(\"All required modules are installed.\")\n",
    "\n",
    "# import the installed libraries ...\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from datetime import datetime\n",
    "import os\n",
    "from configparser import ConfigParser\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from langdetect import detect\n",
    "import langdetect\n",
    "from textblob import TextBlob\n",
    "import calendar\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import DateFormatter\n",
    "from prettytable import PrettyTable\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62382a9-a4eb-4079-88c7-86ff18f981ba",
   "metadata": {},
   "source": [
    "### B. Settings\n",
    "This section specifies the settings for connecting to the YouTube API and collecting the data about YouTube videos and their corresponding comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3914f598-971c-499a-9909-6776720a2221",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VIDEOS_FILE = \"videos.csv\"\n",
    "COMMENTS_FILE = \"comments.csv\"\n",
    "CREDENTIALS_FILE = 'credentials.ini'\n",
    "START_DATE = datetime(2020, 1, 1)\n",
    "END_DATE = datetime(2023, 1, 1)\n",
    "KEYWORDS =['coronavirus', 'covid', 'covid-19', 'pandemic']\n",
    "# You can use functin get_channel_info() to extract the channel ID of a sample video from a news publisher ...\n",
    "CHANNELS = {\n",
    "    'UCXIJgqnII2ZOINSWNOGFThA' : 'Fox News',\n",
    "    'UC16niRr50-MSBwiO3YDb3RA' : 'BBC News',\n",
    "    'UCupvZG-5ko_eiXAupbDfxWw' : 'CNN',\n",
    "    'UCaXkIU1QidjPwiAYu6GcHjg' : 'MSNBC'\n",
    "}\n",
    "MAX_VIDEOS = 50 # the maximum number of video that should be returned for each request. Acceptable values are 0 to 50\n",
    "QUERY= f\"intitle:{','.join(KEYWORDS)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b010ce18-ccee-459e-97bd-73d13e5ad0ec",
   "metadata": {},
   "source": [
    "### C. Load the credentials for authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ea3dfcd6-0ae1-41bc-82c0-f9368d071e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_credentials():\n",
    "    try:\n",
    "        config = ConfigParser(interpolation=None)\n",
    "        config.read(CREDENTIALS_FILE)\n",
    "        developer_key = config.get('credentials_youtube', 'developer_key', fallback=None)\n",
    "        service_name = config.get('credentials_youtube', 'youtube_api_service_name', fallback=None)\n",
    "        service_version = config.get('credentials_youtube', 'youtube_api_version', fallback=None)\n",
    "        if not developer_key or not service_name or not service_version:\n",
    "            raise ValueError(\"Invalid credentials file\")\n",
    "\n",
    "        return {\n",
    "            'developer_key' : developer_key,\n",
    "            'service_name' : service_name,\n",
    "            'service_version' : service_version\n",
    "        }\n",
    "    except Exception as e:\n",
    "        raise ValueError(\"Failed to load credentials: {}\".format(str(e)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03189f46-940d-4822-976e-691e9b0cf503",
   "metadata": {
    "tags": []
   },
   "source": [
    "### D. Extract the channel_id and channel_title of a sample video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8503383a-2975-4339-a921-e8b547735f87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This function takes a video ID and a YouTube Object and returns the video's channel ID\n",
    "# See Section H (call the functions) to learn how to use this function\n",
    "def get_channel_info(video_id, youtube):\n",
    "    request = youtube.videos().list(\n",
    "        part=\"snippet\",\n",
    "        id=video_id\n",
    "    )\n",
    "    response = request.execute()\n",
    "    channel_id = response['items'][0]['snippet']['channelId']\n",
    "    channel_title = response['items'][0]['snippet']['channelTitle']\n",
    "    return channel_id, channel_title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978f3ff2-52f2-4395-8e08-bf4a7c4288e3",
   "metadata": {},
   "source": [
    "### E. Search for the videos from the channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7669b972-7e4c-4248-b705-0c1d2123ca59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_channel_videos(channel_ids, start_date, end_date, query, video_categories={}, max_videos=10):\n",
    "    df_list = []\n",
    "    for channel_id in channel_ids: \n",
    "        print(f\"-> collecting videos for channel: {CHANNELS[channel_id]}\")\n",
    "        try:\n",
    "            request = youtube.search().list(\n",
    "                part=\"snippet\",\n",
    "                type='video',\n",
    "                channelId=channel_id,\n",
    "                maxResults=max_videos, # specifies the maximum number of items that should be returned in the result set. Acceptable values are 0 to 50, inclusive.\n",
    "                q=query,\n",
    "                publishedAfter=start_date.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "                publishedBefore=end_date.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "            )\n",
    "            response = request.execute()\n",
    "            videos = response['items']\n",
    "            data = []\n",
    "            for video in videos:\n",
    "                video_id = video['id']['videoId']\n",
    "                video_details = youtube.videos().list(\n",
    "                    part=\"snippet,statistics,contentDetails\",\n",
    "                    id=video_id\n",
    "                ).execute()\n",
    "                video_data = {\n",
    "                    'video_id' : video_id,\n",
    "                    'channel_id' : channel_id,\n",
    "                    'video_title': video_details['items'][0]['snippet']['title'],\n",
    "                    'channel_title': video_details['items'][0]['snippet']['channelTitle'],\n",
    "                    'category_name': video_categories.get(str(video_details['items'][0]['snippet']['categoryId']), 'Unknown'),\n",
    "                    'live_upcoming_none' : video_details['items'][0]['snippet']['liveBroadcastContent'],\n",
    "                    'view_count': video_details['items'][0]['statistics'].get('viewCount', 0),\n",
    "                    'like_count': video_details['items'][0]['statistics'].get('likeCount', 0),\n",
    "                    'dislike_count': video_details['items'][0]['statistics'].get('dislikeCount', 0),\n",
    "                    'comment_count': video_details['items'][0]['statistics'].get('commentCount', 0),\n",
    "                    'published_at': video_details['items'][0]['snippet']['publishedAt'],\n",
    "                    'tags': ','.join(video_details['items'][0]['snippet'].get('tags', [])),\n",
    "                    'duration': video_details['items'][0]['contentDetails'].get('duration', ''),\n",
    "                    'definition': video_details['items'][0]['contentDetails'].get('definition', 'unknown'),\n",
    "                    'caption': video_details['items'][0]['contentDetails'].get('caption', 'false'),\n",
    "                    'thumbnail' : video_details['items'][0]['snippet']['thumbnails']['default'].get('url'),\n",
    "                    'url': 'https://www.youtube.com/watch?v={}'.format(video_id)\n",
    "                }\n",
    "                data.append(video_data)\n",
    "            df = pd.DataFrame(data)\n",
    "            df_list.append(df)\n",
    "        except HttpError as e:\n",
    "            print(f'An HTTP error {e.resp.status} occurred:\\n{e.content}')\n",
    "        except Exception as e:\n",
    "            print(f'An error occurred:\\n{str(e)}')\n",
    "    df_concatenated = pd.concat(df_list, axis=0)\n",
    "    df_concatenated.to_csv(VIDEOS_FILE, mode='w', index=False)\n",
    "    return df_concatenated\n",
    "\n",
    "print(get_channel_videos())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94d7761-5a07-4c44-a7ed-c4b6302aa0ac",
   "metadata": {},
   "source": [
    "### F. Retrieve comments for a list of videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0b2e63bd-8072-4275-b854-2055d0fb10eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos_comments():\n",
    "    videos = pd.read_csv(VIDEOS_FILE)\n",
    "    video_ids = videos['video_id'].tolist()\n",
    "    df_list =[]    \n",
    "    # Loop through all the video IDs and retrieve the comments\n",
    "    for video_id in video_ids:\n",
    "        print(f\"-> collecting comments for video: {video_id}\")\n",
    "        comments_list = []\n",
    "        try:\n",
    "            response = youtube.commentThreads().list(\n",
    "                part='snippet',\n",
    "                videoId=video_id,\n",
    "                textFormat='plainText'\n",
    "            ).execute()\n",
    "\n",
    "            # Loop through all the comments and extract the relevant information\n",
    "            for item in response['items']:\n",
    "                comment_id = item['snippet']['topLevelComment']['id']\n",
    "                comment_text = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "                comment_author = item['snippet']['topLevelComment']['snippet']['authorDisplayName']\n",
    "                comment_date = item['snippet']['topLevelComment']['snippet']['publishedAt']\n",
    "                like_count = item['snippet']['topLevelComment']['snippet']['likeCount']\n",
    "                reply_count = item['snippet']['totalReplyCount']\n",
    "                comments_list.append([video_id, comment_id, comment_text, comment_author, comment_date, like_count, None])\n",
    "                \n",
    "                if reply_count > 0:\n",
    "                    # Retrieve the replies to the top-level comment\n",
    "                    reply_response = youtube.comments().list(\n",
    "                        part='snippet',\n",
    "                        parentId=comment_id,\n",
    "                        textFormat='plainText'\n",
    "                    ).execute()\n",
    "                    \n",
    "                    # Loop through all the replies and extract the relevant information\n",
    "                    for reply_item in reply_response['items']:\n",
    "                        reply_id = reply_item['id']\n",
    "                        reply_text = reply_item['snippet']['textDisplay']\n",
    "                        reply_author = reply_item['snippet']['authorDisplayName']\n",
    "                        reply_date = reply_item['snippet']['publishedAt']\n",
    "                        reply_like_count = reply_item['snippet']['likeCount']\n",
    "                        comments_list.append([video_id, reply_id, reply_text, reply_author, reply_date, reply_like_count, comment_id])\n",
    "\n",
    "        except HttpError as error:\n",
    "            if error.resp.status == 403:\n",
    "                print(f'Comments are disabled for video ID {video_id}. Skipping...')\n",
    "            else:\n",
    "                raise error\n",
    "        \n",
    "        df = pd.DataFrame(comments_list, columns=['video_id', 'comment_id', 'comment_text', 'comment_author', 'comment_date', 'comment_like_count', 'parent_comment_id'])\n",
    "        df_list.append(df)\n",
    "    df_concatenated = pd.concat(df_list, axis=0)\n",
    "    df_concatenated.to_csv(COMMENTS_FILE, mode='w', index=False)\n",
    "    return df_concatenated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53640a66-446e-470c-9b7d-928367dcfee3",
   "metadata": {},
   "source": [
    "### G. Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4282dba5-9feb-4860-be39-efac070d9827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(VIDEOS_FILE, COMMENTS_FILE, stopwords):\n",
    "    # Load videos data\n",
    "    videos = pd.read_csv(VIDEOS_FILE)\n",
    "\n",
    "    # Clean videos data\n",
    "    videos['video_title'] = videos['video_title'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x) if isinstance(x, str) else x) # remove punctuation\n",
    "    videos['video_title'] = videos['video_title'].apply(lambda x: re.sub(r'\\d+', '', x) if isinstance(x, str) else x) # remove digits\n",
    "    videos['video_title'] = videos['video_title'].apply(lambda x: x.lower() if isinstance(x, str) else x) # convert to lowercase\n",
    "\n",
    "    # Save cleaned videos data to new CSV file, replacing the existing file\n",
    "    videos.to_csv(VIDEOS_FILE, index=False)\n",
    "\n",
    "    # Load comments data\n",
    "    comments = pd.read_csv(COMMENTS_FILE)\n",
    "\n",
    "    # Clean comments data\n",
    "    comments['comment_text'] = comments['comment_text'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x) if isinstance(x, str) else x)  # remove punctuation\n",
    "    comments['comment_text'] = comments['comment_text'].apply(lambda x: re.sub(r'\\d+', '', x) if isinstance(x, str) else x)  # remove digits\n",
    "    comments['comment_text'] = comments['comment_text'].apply(lambda x: x.lower() if isinstance(x, str) else x)  # convert to lowercase\n",
    "\n",
    "    # Remove duplicates\n",
    "    comments = comments.drop_duplicates()\n",
    "\n",
    "    # Remove rows with missing comment_text\n",
    "    comments = comments.dropna(subset=['comment_text'])\n",
    "\n",
    "    # Filter out comments that are not in English\n",
    "    try:\n",
    "        comments = comments[comments['comment_text'].apply(lambda x: langdetect.detect(x) == 'en')]\n",
    "    except langdetect.LangDetectException as e:\n",
    "        print(f\"non-english comment skipped ... {e}\")\n",
    "    # Stopword removal\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    comments['comment_text'] = comments['comment_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "\n",
    "    # Save cleaned comments data to new CSV file, replacing the existing file\n",
    "    comments.to_csv(COMMENTS_FILE, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e72618-4248-458a-b753-bded1ce6f0ff",
   "metadata": {},
   "source": [
    "## H. Call the functions ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "466fb70c-e28c-4b70-8a0b-a74f6fcf2bc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to load credentials: Invalid credentials file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 9\u001b[0m, in \u001b[0;36mload_credentials\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m developer_key \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m service_name \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m service_version:\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid credentials file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeveloper_key\u001b[39m\u001b[38;5;124m'\u001b[39m : developer_key,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mservice_name\u001b[39m\u001b[38;5;124m'\u001b[39m : service_name,\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mservice_version\u001b[39m\u001b[38;5;124m'\u001b[39m : service_version\n\u001b[1;32m     15\u001b[0m }\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid credentials file",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Read the developer_key, service_name, and service_version from credentials.ini \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m credentials \u001b[38;5;241m=\u001b[39m \u001b[43mload_credentials\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Build a youtube object using the build function\u001b[39;00m\n\u001b[1;32m      5\u001b[0m youtube \u001b[38;5;241m=\u001b[39m build(credentials[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mservice_name\u001b[39m\u001b[38;5;124m'\u001b[39m], credentials[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mservice_version\u001b[39m\u001b[38;5;124m'\u001b[39m],developerKey\u001b[38;5;241m=\u001b[39mcredentials[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeveloper_key\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[56], line 17\u001b[0m, in \u001b[0;36mload_credentials\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeveloper_key\u001b[39m\u001b[38;5;124m'\u001b[39m : developer_key,\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mservice_name\u001b[39m\u001b[38;5;124m'\u001b[39m : service_name,\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mservice_version\u001b[39m\u001b[38;5;124m'\u001b[39m : service_version\n\u001b[1;32m     15\u001b[0m     }\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load credentials: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to load credentials: Invalid credentials file"
     ]
    }
   ],
   "source": [
    "# Read the developer_key, service_name, and service_version from credentials.ini \n",
    "credentials = load_credentials()\n",
    "\n",
    "# Build a youtube object using the build function\n",
    "youtube = build(credentials['service_name'], credentials['service_version'],developerKey=credentials['developer_key'])\n",
    "\n",
    "# Exctract the video categories\n",
    "response = youtube.videoCategories().list(part='snippet', regionCode='UK').execute()\n",
    "VIDEO_CATEGORIES = {category['id']: category['snippet']['title'] for category in response['items']}\n",
    "\n",
    "#The following line shows how to extract the channel_id and channel_title of a video with video_id \"OOrW82pHlMQ\"\n",
    "# channel_id, channel_title = get_channel_info('OOrW82pHlMQ', youtube)\n",
    "# print(f'{channel_id}, {channel_title}')\n",
    "\n",
    "#  ------------  Get the data -------------------------------------\n",
    "get_channel_videos(list(CHANNELS.keys()), START_DATE, END_DATE, QUERY, VIDEO_CATEGORIES, max_videos = MAX_VIDEOS).head()\n",
    "print (\"-> Videos have been Collected ---------------------------\")\n",
    "get_videos_comments().head()\n",
    "print (\"-> Comments have been Collected -------------------------\")\n",
    "# -------------- Clean the data -----------------------------------\n",
    "clean_data(VIDEOS_FILE, COMMENTS_FILE, stopwords)\n",
    "print (\"-> Data Cleaning has been Completed ---------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b656c2c-c1b0-4ebf-a228-b3b7e4634957",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "2920b276a3ebce4ce72dc8ffba4d2570b82a96386913ad33f11b89ba088715fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
